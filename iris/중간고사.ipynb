{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(72.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "w = torch.tensor(4.0, requires_grad=True)\n",
    "a = w * 3\n",
    "l = a ** 2\n",
    "l.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4088],\n",
      "        [ 0.6673]]) tensor([0.3574])\n",
      "0 87.33390808105469 tensor([-0.0834,  1.2884]) tensor([0.4690])\n",
      "100 1.9493783712387085 tensor([0.3724, 3.2251]) tensor([-1.0386])\n",
      "200 0.9835619926452637 tensor([0.7565, 3.2172]) tensor([-1.9300])\n",
      "300 0.5052369832992554 tensor([1.0999, 3.1620]) tensor([-2.5221])\n",
      "400 0.2596477270126343 tensor([1.3537, 3.1169]) tensor([-2.9412])\n",
      "500 0.13343767821788788 tensor([1.5366, 3.0839]) tensor([-3.2410])\n",
      "600 0.0685761421918869 tensor([1.6678, 3.0601]) tensor([-3.4559])\n",
      "700 0.035242579877376556 tensor([1.7618, 3.0431]) tensor([-3.6100])\n",
      "800 0.018111784011125565 tensor([1.8293, 3.0309]) tensor([-3.7204])\n",
      "900 0.00930803082883358 tensor([1.8776, 3.0222]) tensor([-3.7996])\n",
      "1000 0.004783623851835728 tensor([1.9123, 3.0159]) tensor([-3.8563])\n",
      "1100 0.002458409871906042 tensor([1.9371, 3.0114]) tensor([-3.8970])\n",
      "1200 0.0012633815640583634 tensor([1.9549, 3.0082]) tensor([-3.9262])\n",
      "1300 0.0006492786342278123 tensor([1.9677, 3.0059]) tensor([-3.9471])\n",
      "1400 0.0003336890658829361 tensor([1.9768, 3.0042]) tensor([-3.9620])\n",
      "1500 0.00017149077029898763 tensor([1.9834, 3.0030]) tensor([-3.9728])\n",
      "1600 8.813705062493682e-05 tensor([1.9881, 3.0022]) tensor([-3.9805])\n",
      "1700 4.529933357844129e-05 tensor([1.9915, 3.0015]) tensor([-3.9860])\n",
      "1800 2.327797483303584e-05 tensor([1.9939, 3.0011]) tensor([-3.9900])\n",
      "1900 1.1961803465965204e-05 tensor([1.9956, 3.0008]) tensor([-3.9928])\n",
      "2000 6.1481814555008896e-06 tensor([1.9969, 3.0006]) tensor([-3.9948])\n",
      "2100 3.1594433949067025e-06 tensor([1.9977, 3.0004]) tensor([-3.9963])\n",
      "2200 1.6246664245045395e-06 tensor([1.9984, 3.0003]) tensor([-3.9974])\n",
      "2300 8.351009341822646e-07 tensor([1.9988, 3.0002]) tensor([-3.9981])\n",
      "2400 4.289991863970499e-07 tensor([1.9992, 3.0002]) tensor([-3.9986])\n",
      "2500 2.2034851099306252e-07 tensor([1.9994, 3.0001]) tensor([-3.9990])\n",
      "2600 1.1377071729157251e-07 tensor([1.9996, 3.0001]) tensor([-3.9993])\n",
      "2700 5.838554528736495e-08 tensor([1.9997, 3.0001]) tensor([-3.9995])\n",
      "2800 3.019296102024782e-08 tensor([1.9998, 3.0000]) tensor([-3.9996])\n",
      "2900 1.5426177668587115e-08 tensor([1.9998, 3.0000]) tensor([-3.9997])\n",
      "3000 8.038583132474741e-09 tensor([1.9999, 3.0000]) tensor([-3.9998])\n"
     ]
    }
   ],
   "source": [
    "#linear regression\n",
    "x_train = torch.FloatTensor([[1, 2], [3, 2], [3, 7], [1, 1], [1, 0]])\n",
    "y_train = torch.FloatTensor([[4], [8], [23], [1], [-2]])\n",
    "w = torch.randn(2, 1)\n",
    "b = torch.randn(1)\n",
    "print(w, b)\n",
    "\n",
    "lr = 0.01\n",
    "for epoch in range(3001):\n",
    "    w.requires_grad_(True)\n",
    "    b.requires_grad_(True)\n",
    "    \n",
    "    h = x_train @ w + b\n",
    "    cost = ((h - y_train) ** 2).mean()\n",
    "    \n",
    "    cost.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w = w - lr * w.grad\n",
    "        b = b - lr * b.grad\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, cost.item(), w.squeeze(), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "x_train=torch.FloatTensor([[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]])\n",
    "y_train=torch.FloatTensor([[1],[1],[1],[0],[0],[0],[0],[1],[0],[1],[1],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 3.]] [-4.]\n",
      "[[36.]\n",
      " [21.]\n",
      " [25.]]\n"
     ]
    }
   ],
   "source": [
    "#linear_regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "x = [[1, 2], [3, 2], [3, 7], [1, 1], [1, 0]]\n",
    "y = [[4], [8], [23], [1], [-2]]\n",
    "\n",
    "lr.fit(x, y)\n",
    "#실제로 scikit-learn에서 구하는 coef(w)와 intercept(b)는 경사하강법이 아니다. \n",
    "print(lr.coef_, lr.intercept_)\n",
    "\n",
    "x_test = [[5, 10], [2, 7], [10, 3]]\n",
    "y_test = lr.predict(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.2426789999008179 -0.2901606559753418 1.406509518623352\n",
      "100 0.4157479703426361 -1.5245215892791748 4.632030963897705\n",
      "200 0.3973163664340973 -1.9400299787521362 5.900088310241699\n",
      "300 0.3901863098144531 -2.2024333477020264 6.694453716278076\n",
      "400 0.3866744339466095 -2.387808322906494 7.253246784210205\n",
      "500 0.3847322165966034 -2.5261824131011963 7.669256687164307\n",
      "600 0.3835822641849518 -2.632913589477539 7.989555835723877\n",
      "700 0.38287022709846497 -2.7170357704162598 8.241677284240723\n",
      "800 0.38241544365882874 -2.784351110458374 8.443233489990234\n",
      "900 0.3821180760860443 -2.8388216495513916 8.606206893920898\n",
      "1000 0.3819204568862915 -2.883270502090454 8.739119529724121\n",
      "1100 0.3817872107028961 -2.919776201248169 8.84822940826416\n",
      "1200 0.38169658184051514 -2.94991397857666 8.938273429870605\n",
      "1300 0.381634384393692 -2.9748964309692383 9.01289176940918\n",
      "1400 0.3815912902355194 -2.9956700801849365 9.074923515319824\n",
      "1500 0.38156139850616455 -3.0129921436309814 9.126638412475586\n",
      "1600 0.3815406262874603 -3.0274689197540283 9.169852256774902\n",
      "1700 0.38152584433555603 -3.0395891666412354 9.206026077270508\n",
      "1800 0.3815155327320099 -3.0497498512268066 9.236348152160645\n",
      "1900 0.38150835037231445 -3.0582799911499023 9.261801719665527\n",
      "2000 0.38150325417518616 -3.065446376800537 9.283185005187988\n",
      "2100 0.38149964809417725 -3.0714735984802246 9.301167488098145\n",
      "2200 0.38149702548980713 -3.0765459537506104 9.316300392150879\n",
      "2300 0.3814952075481415 -3.080817222595215 9.329042434692383\n",
      "2400 0.3814939260482788 -3.084415912628174 9.339776992797852\n",
      "2500 0.38149306178092957 -3.0874485969543457 9.348823547363281\n",
      "2600 0.3814924657344818 -3.090006113052368 9.356451988220215\n",
      "2700 0.38149189949035645 -3.092163562774658 9.362887382507324\n",
      "2800 0.38149163126945496 -3.0939834117889404 9.368315696716309\n",
      "2900 0.3814913332462311 -3.0955188274383545 9.372896194458008\n",
      "3000 0.38149118423461914 -3.096815347671509 9.376762390136719\n"
     ]
    }
   ],
   "source": [
    "#bce를 통한 분류\n",
    "\n",
    "bce = torch.nn.BCELoss()\n",
    "\n",
    "import math\n",
    "w = torch.randn(1, 1)\n",
    "b = torch.randn(1, 1)\n",
    "\n",
    "lr = 1.0\n",
    "\n",
    "for epoch in range(3001):\n",
    "    w.requires_grad_(True)\n",
    "    b.requires_grad_(True)\n",
    "    \n",
    "    h = torch.sigmoid(x_train @ w + b)\n",
    "    # h = 1 / (1 + math.e ** (-(x_train @ w + b)))\n",
    "    \n",
    "    # cost = torch.mean(-y_train * torch.log(h) - (1 - y_train) * torch.log(1 - h))\n",
    "    cost = bce(h, y_train)\n",
    "    cost.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w = w - lr * w.grad\n",
    "        b = b - lr * b.grad\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, cost.item(), w.item(), b.item())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "x_test = torch.FloatTensor([[4.5], [1.1]])    \n",
    "test_result = torch.sigmoid(x_test @ w + b)\n",
    "\n",
    "# print(test_result)\n",
    "print(torch.round(test_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0753892660140991 -0.35750263929367065 -1.4853863716125488\n",
      "100 0.4057193696498871 -1.7229758501052856 5.248586177825928\n",
      "200 0.39578214287757874 -2.321934461593628 7.329427719116211\n",
      "300 0.3829352855682373 -2.7079761028289795 8.239358901977539\n",
      "400 0.38259825110435486 -2.8705146312713623 8.803410530090332\n",
      "500 0.3828332722187042 -2.960695266723633 9.111281394958496\n",
      "600 0.3837950527667999 -3.0035133361816406 9.292625427246094\n",
      "700 0.3843172788619995 -3.031177520751953 9.393213272094727\n",
      "800 0.38399538397789 -3.0527501106262207 9.4443359375\n",
      "900 0.3839006721973419 -3.0637941360473633 9.474421501159668\n",
      "1000 0.3839716613292694 -3.0689494609832764 9.492876052856445\n",
      "1100 0.383990615606308 -3.0722286701202393 9.503206253051758\n",
      "1200 0.38397467136383057 -3.0743515491485596 9.50886344909668\n",
      "1300 0.3839724361896515 -3.0754806995391846 9.512185096740723\n",
      "1400 0.38397645950317383 -3.076082706451416 9.514141082763672\n",
      "1500 0.3839770555496216 -3.0764498710632324 9.515246391296387\n",
      "1600 0.38397613167762756 -3.0766706466674805 9.51586627960205\n",
      "1700 0.3839762210845947 -3.0767905712127686 9.516230583190918\n",
      "1800 0.3839764893054962 -3.076857328414917 9.516440391540527\n",
      "1900 0.38397645950317383 -3.0768985748291016 9.516560554504395\n",
      "2000 0.3839764893054962 -3.076921224594116 9.516629219055176\n",
      "2100 0.383976548910141 -3.0769340991973877 9.516667366027832\n",
      "2200 0.38397642970085144 -3.0769405364990234 9.516685485839844\n",
      "2300 0.38397642970085144 -3.076944589614868 9.516695976257324\n",
      "2400 0.38397642970085144 -3.0769455432891846 9.516700744628906\n",
      "2500 0.3839764893054962 -3.0769457817077637 9.516700744628906\n",
      "2600 0.3839764893054962 -3.0769457817077637 9.516700744628906\n",
      "2700 0.3839764893054962 -3.0769457817077637 9.516700744628906\n",
      "2800 0.3839764893054962 -3.0769457817077637 9.516700744628906\n",
      "2900 0.3839764893054962 -3.0769457817077637 9.516700744628906\n",
      "3000 0.3839764893054962 -3.0769457817077637 9.516700744628906\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn(1, 1, requires_grad=True)\n",
    "b = torch.randn(1, 1, requires_grad=True)\n",
    "\n",
    "# optimizer = torch.optim.Adam([w, b], lr=1.0)\n",
    "# optimizer = torch.optim.SGD([w, b], lr=1.0)\n",
    "optimizer = torch.optim.RMSprop([w, b], lr=0.1)\n",
    "\n",
    "\n",
    "for epoch in range(3001):\n",
    "    \n",
    "    h = torch.sigmoid(x_train @ w + b)\n",
    "    cost = torch.mean(-y_train * torch.log(h) - (1 - y_train) * torch.log(1 - h))\n",
    "    \n",
    "    #누적된 기울기 초기화\n",
    "    optimizer.zero_grad()\n",
    "    #기울기, 편향 계산\n",
    "    cost.backward()\n",
    "    \n",
    "    #가중치 업데이트\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, cost.item(), w.item(), b.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, cost:2.2546908855438232\n",
      "epoch:100, cost:0.31657472252845764\n",
      "epoch:200, cost:0.2015831470489502\n",
      "epoch:300, cost:0.13777488470077515\n",
      "epoch:400, cost:0.1002374067902565\n",
      "epoch:500, cost:0.07629694044589996\n",
      "epoch:600, cost:0.060033608227968216\n",
      "epoch:700, cost:0.04845796525478363\n",
      "epoch:800, cost:0.03991863131523132\n",
      "epoch:900, cost:0.033436369150877\n",
      "epoch:1000, cost:0.0283978171646595\n",
      "epoch:1100, cost:0.02440267987549305\n",
      "epoch:1200, cost:0.021180428564548492\n",
      "epoch:1300, cost:0.018542766571044922\n",
      "epoch:1400, cost:0.016355669125914574\n",
      "epoch:1500, cost:0.014521420933306217\n",
      "epoch:1600, cost:0.012967719696462154\n",
      "epoch:1700, cost:0.01163968164473772\n",
      "epoch:1800, cost:0.010495397262275219\n",
      "epoch:1900, cost:0.009502395987510681\n",
      "epoch:2000, cost:0.008635029196739197\n",
      "epoch:2100, cost:0.007872886955738068\n",
      "epoch:2200, cost:0.007199637126177549\n",
      "epoch:2300, cost:0.0066019101068377495\n",
      "epoch:2400, cost:0.0060689738020300865\n",
      "epoch:2500, cost:0.0055917659774422646\n",
      "epoch:2600, cost:0.005162868648767471\n",
      "epoch:2700, cost:0.0047759911976754665\n",
      "epoch:2800, cost:0.004425950814038515\n",
      "epoch:2900, cost:0.004108223132789135\n",
      "epoch:3000, cost:0.0038190935738384724\n"
     ]
    }
   ],
   "source": [
    "#softmax\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "x_train = torch.tensor([ [1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], [4, 1, 5, 5], [1, 7, 5, 5],\n",
    "                            [1, 2, 5, 6], [1, 6, 6, 6], [1, 7, 7, 7] ], dtype=torch.float)\n",
    "y_train = torch.tensor([ 2, 2, 2, 1, 1, 1, 0, 0], dtype=torch.long)\n",
    "\n",
    "# W = torch.randn(4, 3, requires_grad=True)\n",
    "# b = torch.randn(1, 3, requires_grad=True)\n",
    "\n",
    "# optim = torch.optim.Adam([W, b], lr=0.1)\n",
    "model = nn.Linear(4, 3)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "for epoch in range(3001):\n",
    "    \n",
    "    # h = torch.mm(x_train, W) + b\n",
    "    h = model(x_train)\n",
    "    #cost 계산\n",
    "    \n",
    "    cost = F.cross_entropy(h, y_train)\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    cost.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch:{epoch}, cost:{cost.item()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_train = np.array([ [1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], [4, 1, 5, 5], [1, 7, 5, 5],\n",
    "                            [1, 2, 5, 6], [1, 6, 6, 6], [1, 7, 7, 7] ])\n",
    "y_train = np.array([ 2, 2, 2, 1, 1, 1, 0, 0])\n",
    "\n",
    "#y 에 0, 1, 2 등 둘 이상의 class가 존재 => softmax regression\n",
    "model = LogisticRegression(penalty=None)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "x_test = np.array([[1, 11, 10, 9], [1, 3, 4, 3], [1, 1, 0, 1]])\n",
    "model.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, cost:8.982460021972656\n",
      "epoch:100, cost:0.3560991585254669\n",
      "epoch:200, cost:0.23404189944267273\n",
      "epoch:300, cost:0.1653594672679901\n",
      "epoch:400, cost:0.12284959107637405\n",
      "epoch:500, cost:0.0947890430688858\n",
      "epoch:600, cost:0.07527570426464081\n",
      "epoch:700, cost:0.06115284189581871\n",
      "epoch:800, cost:0.05060599371790886\n",
      "epoch:900, cost:0.042526327073574066\n",
      "epoch:1000, cost:0.03620282933115959\n",
      "epoch:1100, cost:0.031162874773144722\n",
      "epoch:1200, cost:0.027081714943051338\n",
      "epoch:1300, cost:0.023730918765068054\n",
      "epoch:1400, cost:0.020946018397808075\n",
      "epoch:1500, cost:0.018606187775731087\n",
      "epoch:1600, cost:0.016621368005871773\n",
      "epoch:1700, cost:0.014922989532351494\n",
      "epoch:1800, cost:0.013458430767059326\n",
      "epoch:1900, cost:0.012186627835035324\n",
      "epoch:2000, cost:0.011075077578425407\n",
      "epoch:2100, cost:0.010098040103912354\n",
      "epoch:2200, cost:0.009234645403921604\n",
      "epoch:2300, cost:0.008468003012239933\n",
      "epoch:2400, cost:0.007784293964505196\n",
      "epoch:2500, cost:0.007171948440372944\n",
      "epoch:2600, cost:0.0066215889528393745\n",
      "epoch:2700, cost:0.0061251637525856495\n",
      "epoch:2800, cost:0.005675904918462038\n",
      "epoch:2900, cost:0.00526818260550499\n",
      "epoch:3000, cost:0.004897152539342642\n"
     ]
    }
   ],
   "source": [
    "#softmax\n",
    "x_train = torch.tensor([ [1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], [4, 1, 5, 5], [1, 7, 5, 5],\n",
    "                            [1, 2, 5, 6], [1, 6, 6, 6], [1, 7, 7, 7] ], dtype=torch.float)\n",
    "y_train = torch.tensor([[0,0,1], [0,0,1], [0,0,1], [0,1,0], [0,1,0], \n",
    "                       [0,1,0], [1,0,0], [1,0,0]], dtype=torch.float)\n",
    "\n",
    "W = torch.randn(4, 3, requires_grad=True)\n",
    "b = torch.randn(1, 3, requires_grad=True)\n",
    "\n",
    "optim = torch.optim.Adam([W, b], lr=0.1)\n",
    "\n",
    "for epoch in range(3001):\n",
    "    #어디를 합을 1로 만들건지(dim=0 or 1)\n",
    "    h = torch.softmax(torch.mm(x_train, W) + b, dim=1)   \n",
    "    #cost 계산\n",
    "    cost = -torch.mean(torch.sum(y_train * torch.log(h), dim=1))\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    cost.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch:{epoch}, cost:{cost.item()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.tensor([[1, 11, 10, 9], [1, 3, 4, 3], [1, 1, 0, 1]], dtype=torch.float)\n",
    "\n",
    "h = torch.softmax(torch.mm(x_test, W) + b, dim = 1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소프트맥스 확률 출력:\n",
      "tensor([[0.6590, 0.2424, 0.0986],\n",
      "        [0.1131, 0.8360, 0.0508],\n",
      "        [0.1220, 0.3315, 0.5465]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 입력 데이터 준비 (logits)\n",
    "logits = torch.tensor([[2.0, 1.0, 0.1],\n",
    "                       [1.0, 3.0, 0.2],\n",
    "                       [0.5, 1.5, 2.0]])\n",
    "\n",
    "# 소프트맥스 적용\n",
    "softmax_probs = F.softmax(logits, dim=1)\n",
    "\n",
    "print(\"소프트맥스 확률 출력:\")\n",
    "print(softmax_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#softmax\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_train = np.array([ [1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], [4, 1, 5, 5], [1, 7, 5, 5],\n",
    "                            [1, 2, 5, 6], [1, 6, 6, 6], [1, 7, 7, 7] ])\n",
    "y_train = np.array([ 2, 2, 2, 1, 1, 1, 0, 0])\n",
    "\n",
    "model = LogisticRegression(penalty=None)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "x_test = np.array([[1, 11, 10, 9], [1, 3, 4, 3], [1, 1, 0, 1]])\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy 손실: 0.8106180429458618\n",
      "Binary Cross Entropy 손실: 0.14462153613567352\n"
     ]
    }
   ],
   "source": [
    "#cross entropy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 다중 클래스 예제 (CrossEntropyLoss)\n",
    "y_true = torch.tensor([2, 0])  # 실제 값 (원-핫 인코딩이 아님, 클래스 인덱스로 전달)\n",
    "y_pred = torch.tensor([[0.1, 0.3, 0.6], [0.7, 0.2, 0.1]])  # 예측 값 (로짓 값)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(y_pred, y_true)\n",
    "print(f\"Cross Entropy 손실: {loss.item()}\")\n",
    "\n",
    "# 이진 분류 예제 (BCELoss)\n",
    "y_true_binary = torch.tensor([1.0, 0.0, 1.0])  # 실제 값\n",
    "y_pred_binary = torch.tensor([0.9, 0.1, 0.8])  # 예측 값\n",
    "\n",
    "bce_criterion = nn.BCELoss()\n",
    "bce_loss = bce_criterion(y_pred_binary, y_true_binary)\n",
    "print(f\"Binary Cross Entropy 손실: {bce_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/500], Loss: 1.6165\n",
      "Epoch [50/500], Loss: 1.0411\n",
      "Epoch [100/500], Loss: 0.7446\n",
      "Epoch [150/500], Loss: 0.5553\n",
      "Epoch [200/500], Loss: 0.4265\n",
      "Epoch [250/500], Loss: 0.3365\n",
      "Epoch [300/500], Loss: 0.2717\n",
      "Epoch [350/500], Loss: 0.2240\n",
      "Epoch [400/500], Loss: 0.1878\n",
      "Epoch [450/500], Loss: 0.1599\n",
      "Predicted class for tensor([[1., 0.]]): 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 데이터셋 준비\n",
    "x_train = torch.tensor([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0], [0.0, 0.0]])\n",
    "y_train = torch.tensor([0, 1, 2, 3])  # 클래스 레이블 (0, 1, 2, 3)\n",
    "\n",
    "# 모델 정의\n",
    "class SoftmaxClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SoftmaxClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)  # 입력과 출력 연결\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = SoftmaxClassifier(input_dim=2, output_dim=4)\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()  # 내부적으로 Softmax 포함\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  # Adam Optimizer 사용\n",
    "\n",
    "# 학습 반복 (Epoch Loop)\n",
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    # Forward Propagation\n",
    "    output = model(x_train)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = criterion(output, y_train)\n",
    "\n",
    "    # Gradient 초기화, Backpropagation, 가중치 업데이트\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 중간 결과 출력\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 테스트\n",
    "test_input = torch.tensor([[1.0, 0.0]])  # 새로운 데이터 예측\n",
    "test_output = model(test_input)\n",
    "predicted_class = torch.argmax(test_output, dim=1)\n",
    "print(f\"Predicted class for {test_input}: {predicted_class.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 포인트 정의\n",
    "data = np.array([[1, 2], [2, 1], [4, 5], [5, 4], [8, 8], [9, 9]])\n",
    "\n",
    "# WCSS 저장 리스트\n",
    "wcss = []\n",
    "\n",
    "# 다양한 K 값에 대해 K-Means 수행 (데이터 포인트 개수를 초과하지 않도록 설정)\n",
    "for k in range(1, len(data) + 1):\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "    kmeans.fit(data)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# 엘보우 방법을 위한 그래프 그리기\n",
    "plt.plot(range(1, len(data) + 1), wcss)\n",
    "plt.title('elbow')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('WCSS (Within-Cluster Sum of Squares)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for line in open(\"iris.data\", \"r\"):\n",
    "    line = line.rstrip()\n",
    "    if line == \"\": continue\n",
    "\n",
    "    *x, y = line.split(\",\")\n",
    "    x = [float(i) for i in x]\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    \n",
    "\n",
    "labels = list(set(Y))\n",
    "Y = [labels.index(y) for y in Y]\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def predict(self, queries):\n",
    "        Y = []\n",
    "        for q in queries:\n",
    "            dists = np.linalg.norm(self.X - q, axis = 1)\n",
    "            knns= np.argsort(dists)[:self.k]\n",
    "            counts = np.bincount(self.Y[knns])\n",
    "            Y.append(np.argmax(counts))\n",
    "\n",
    "        return np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9583333333333334\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "perm = np.random.permutation(len(X))\n",
    "n_trains = int(len(X) * 0.8)\n",
    "X_train = X[perm[:n_trains]]\n",
    "Y_train = Y[perm[:n_trains]]\n",
    "X_test = X[perm[n_trains:]]\n",
    "Y_test = Y[perm[n_trains:]]\n",
    "\n",
    "knn = KNNClassifier(5)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "pred_train = knn.predict(X_train)\n",
    "pred_test = knn.predict(X_test)\n",
    "\n",
    "print(\"Train accuracy:\", (pred_train == Y_train).mean())\n",
    "print(\"Test accuracy:\", (pred_test == Y_test).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
