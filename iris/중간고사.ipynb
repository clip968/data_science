{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(72.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "w = torch.tensor(4.0, requires_grad=True)\n",
    "a = w * 3\n",
    "l = a ** 2\n",
    "l.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5060],\n",
      "        [-0.0581]]) tensor([0.9194])\n",
      "0 98.21588897705078 tensor([0.8214, 0.5945]) tensor([1.0216])\n",
      "100 1.9781043529510498 tensor([0.4977, 3.1472]) tensor([-1.0084])\n",
      "200 0.9576786756515503 tensor([0.7853, 3.2057]) tensor([-1.9505])\n",
      "300 0.491412878036499 tensor([1.1136, 3.1588]) tensor([-2.5415])\n",
      "400 0.2525363564491272 tensor([1.3628, 3.1152]) tensor([-2.9557])\n",
      "500 0.12978298962116241 tensor([1.5430, 3.0827]) tensor([-3.2515])\n",
      "600 0.06669775396585464 tensor([1.6724, 3.0593]) tensor([-3.4634])\n",
      "700 0.03427721560001373 tensor([1.7651, 3.0425]) tensor([-3.6153])\n",
      "800 0.017615653574466705 tensor([1.8316, 3.0305]) tensor([-3.7242])\n",
      "900 0.009052936919033527 tensor([1.8793, 3.0218]) tensor([-3.8023])\n",
      "1000 0.004652451723814011 tensor([1.9135, 3.0157]) tensor([-3.8583])\n",
      "1100 0.002391018206253648 tensor([1.9380, 3.0112]) tensor([-3.8984])\n",
      "1200 0.0012287864228710532 tensor([1.9555, 3.0080]) tensor([-3.9272])\n",
      "1300 0.0006314880447462201 tensor([1.9681, 3.0058]) tensor([-3.9478])\n",
      "1400 0.00032454580650664866 tensor([1.9771, 3.0041]) tensor([-3.9626])\n",
      "1500 0.00016678575775586069 tensor([1.9836, 3.0030]) tensor([-3.9732])\n",
      "1600 8.572570368414745e-05 tensor([1.9883, 3.0021]) tensor([-3.9808])\n",
      "1700 4.405573781696148e-05 tensor([1.9916, 3.0015]) tensor([-3.9862])\n",
      "1800 2.2642891053692438e-05 tensor([1.9940, 3.0011]) tensor([-3.9901])\n",
      "1900 1.1639252988970838e-05 tensor([1.9957, 3.0008]) tensor([-3.9929])\n",
      "2000 5.981016329315025e-06 tensor([1.9969, 3.0006]) tensor([-3.9949])\n",
      "2100 3.0745636649953667e-06 tensor([1.9978, 3.0004]) tensor([-3.9964])\n",
      "2200 1.5798350432305597e-06 tensor([1.9984, 3.0003]) tensor([-3.9974])\n",
      "2300 8.126260695462406e-07 tensor([1.9989, 3.0002]) tensor([-3.9981])\n",
      "2400 4.1784710447245743e-07 tensor([1.9992, 3.0001]) tensor([-3.9987])\n",
      "2500 2.1457415755321563e-07 tensor([1.9994, 3.0001]) tensor([-3.9990])\n",
      "2600 1.1070780914224088e-07 tensor([1.9996, 3.0001]) tensor([-3.9993])\n",
      "2700 5.7030216993325666e-08 tensor([1.9997, 3.0001]) tensor([-3.9995])\n",
      "2800 2.9331124196119163e-08 tensor([1.9998, 3.0000]) tensor([-3.9996])\n",
      "2900 1.5015555021591354e-08 tensor([1.9998, 3.0000]) tensor([-3.9997])\n",
      "3000 7.790026401721661e-09 tensor([1.9999, 3.0000]) tensor([-3.9998])\n"
     ]
    }
   ],
   "source": [
    "#linear regression\n",
    "x_train = torch.FloatTensor([[1, 2], [3, 2], [3, 7], [1, 1], [1, 0]])\n",
    "y_train = torch.FloatTensor([[4], [8], [23], [1], [-2]])\n",
    "w = torch.randn(2, 1)\n",
    "b = torch.randn(1)\n",
    "print(w, b)\n",
    "\n",
    "lr = 0.01\n",
    "for epoch in range(3001):\n",
    "    w.requires_grad_(True)\n",
    "    b.requires_grad_(True)\n",
    "    \n",
    "    h = x_train @ w + b\n",
    "    cost = ((h - y_train) ** 2).mean()\n",
    "    \n",
    "    cost.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w = w - lr * w.grad\n",
    "        b = b - lr * b.grad\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, cost.item(), w.squeeze(), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "x_train=torch.FloatTensor([[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]])\n",
    "y_train=torch.FloatTensor([[1],[1],[1],[0],[0],[0],[0],[1],[0],[1],[1],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 3.]] [-4.]\n",
      "[[36.]\n",
      " [21.]\n",
      " [25.]]\n"
     ]
    }
   ],
   "source": [
    "#linear_regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "x = [[1, 2], [3, 2], [3, 7], [1, 1], [1, 0]]\n",
    "y = [[4], [8], [23], [1], [-2]]\n",
    "\n",
    "lr.fit(x, y)\n",
    "#실제로 scikit-learn에서 구하는 coef(w)와 intercept(b)는 경사하강법이 아니다. \n",
    "print(lr.coef_, lr.intercept_)\n",
    "\n",
    "x_test = [[5, 10], [2, 7], [10, 3]]\n",
    "y_test = lr.predict(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.9661803245544434 -1.0364898443222046 1.916930079460144\n",
      "100 0.41272544860839844 -1.5784704685211182 4.797499179840088\n",
      "200 0.39630356431007385 -1.9716253280639648 5.995969295501709\n",
      "300 0.38971826434135437 -2.224031686782837 6.759653091430664\n",
      "400 0.38642463088035583 -2.4036364555358887 7.300878524780273\n",
      "500 0.38458773493766785 -2.5382494926452637 7.705493450164795\n",
      "600 0.3834940493106842 -2.6423490047454834 8.01784896850586\n",
      "700 0.38281455636024475 -2.7245430946350098 8.264164924621582\n",
      "800 0.3823793828487396 -2.7903997898101807 8.461336135864258\n",
      "900 0.3820943534374237 -2.8437418937683105 8.620923042297363\n",
      "1000 0.3819044828414917 -2.887302875518799 8.751173973083496\n",
      "1100 0.3817765414714813 -2.923100471496582 8.858162879943848\n",
      "1200 0.3816891610622406 -2.952665328979492 8.946491241455078\n",
      "1300 0.38162922859191895 -2.9771792888641357 9.019708633422852\n",
      "1400 0.3815877437591553 -2.997572183609009 9.08060359954834\n",
      "1500 0.3815588653087616 -3.0145821571350098 9.13138484954834\n",
      "1600 0.3815387189388275 -3.028799057006836 9.173822402954102\n",
      "1700 0.3815246820449829 -3.040703058242798 9.2093505859375\n",
      "1800 0.3815147876739502 -3.0506842136383057 9.239136695861816\n",
      "1900 0.3815077543258667 -3.0590643882751465 9.264142036437988\n",
      "2000 0.3815028667449951 -3.066105604171753 9.285151481628418\n",
      "2100 0.381499320268631 -3.0720274448394775 9.30281925201416\n",
      "2200 0.3814968764781952 -3.077012062072754 9.317689895629883\n",
      "2300 0.3814951181411743 -3.081209897994995 9.330212593078613\n",
      "2400 0.38149383664131165 -3.0847463607788086 9.340763092041016\n",
      "2500 0.38149306178092957 -3.0877273082733154 9.349655151367188\n",
      "2600 0.38149240612983704 -3.090240955352783 9.357152938842773\n",
      "2700 0.38149192929267883 -3.0923619270324707 9.363479614257812\n",
      "2800 0.38149163126945496 -3.094151020050049 9.368815422058105\n",
      "2900 0.3814913034439087 -3.095660924911499 9.373319625854492\n",
      "3000 0.38149118423461914 -3.096935272216797 9.377120971679688\n"
     ]
    }
   ],
   "source": [
    "#bce를 통한 분류\n",
    "\n",
    "bce = torch.nn.BCELoss()\n",
    "\n",
    "import math\n",
    "w = torch.randn(1, 1)\n",
    "b = torch.randn(1, 1)\n",
    "\n",
    "lr = 1.0\n",
    "\n",
    "for epoch in range(3001):\n",
    "    w.requires_grad_(True)\n",
    "    b.requires_grad_(True)\n",
    "    \n",
    "    h = torch.sigmoid(x_train @ w + b)\n",
    "    # h = 1 / (1 + math.e ** (-(x_train @ w + b)))\n",
    "    \n",
    "    # cost = torch.mean(-y_train * torch.log(h) - (1 - y_train) * torch.log(1 - h))\n",
    "    cost = bce(h, y_train)\n",
    "    cost.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w = w - lr * w.grad\n",
    "        b = b - lr * b.grad\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, cost.item(), w.item(), b.item())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "x_test = torch.FloatTensor([[4.5], [1.1]])    \n",
    "test_result = torch.sigmoid(x_test @ w + b)\n",
    "\n",
    "# print(test_result)\n",
    "print(torch.round(test_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.8934297561645508 0.13298237323760986 -0.7817929983139038\n",
      "100 0.39995619654655457 -1.8660157918930054 5.685833930969238\n",
      "200 0.38508322834968567 -2.507239580154419 7.5969390869140625\n",
      "300 0.38249969482421875 -2.7933225631713867 8.434892654418945\n",
      "400 0.38236042857170105 -2.9616315364837646 8.872175216674805\n",
      "500 0.3837880790233612 -3.0678250789642334 9.095926284790039\n",
      "600 0.38470616936683655 -3.1221742630004883 9.228002548217773\n",
      "700 0.384000301361084 -3.141711711883545 9.313289642333984\n",
      "800 0.3838374614715576 -3.1554179191589355 9.358614921569824\n",
      "900 0.38397887349128723 -3.165482997894287 9.382452964782715\n",
      "1000 0.3840128183364868 -3.1706461906433105 9.396854400634766\n",
      "1100 0.3839809000492096 -3.173128128051758 9.405549049377441\n",
      "1200 0.38397660851478577 -3.1747119426727295 9.410340309143066\n",
      "1300 0.38398441672325134 -3.175713539123535 9.413006782531738\n",
      "1400 0.3839852511882782 -3.176248550415039 9.414586067199707\n",
      "1500 0.3839837610721588 -3.1765382289886475 9.415507316589355\n",
      "1600 0.38398393988609314 -3.1767144203186035 9.416024208068848\n",
      "1700 0.3839842975139618 -3.1768176555633545 9.4163179397583\n",
      "1800 0.383984237909317 -3.176875352859497 9.416487693786621\n",
      "1900 0.3839839696884155 -3.176905870437622 9.41658878326416\n",
      "2000 0.38398411870002747 -3.1769261360168457 9.416644096374512\n",
      "2100 0.38398420810699463 -3.176938772201538 9.416678428649902\n",
      "2200 0.38398420810699463 -3.176941394805908 9.41668701171875\n",
      "2300 0.3839840888977051 -3.1769421100616455 9.416692733764648\n",
      "2400 0.383984237909317 -3.1769442558288574 9.416695594787598\n",
      "2500 0.38398420810699463 -3.1769447326660156 9.416696548461914\n",
      "2600 0.3839842975139618 -3.1769444942474365 9.41669750213623\n",
      "2700 0.383984237909317 -3.1769449710845947 9.41669750213623\n",
      "2800 0.38398420810699463 -3.176945924758911 9.41670036315918\n",
      "2900 0.38398420810699463 -3.176945924758911 9.41670036315918\n",
      "3000 0.38398420810699463 -3.176945924758911 9.41670036315918\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn(1, 1, requires_grad=True)\n",
    "b = torch.randn(1, 1, requires_grad=True)\n",
    "\n",
    "# optimizer = torch.optim.Adam([w, b], lr=1.0)\n",
    "# optimizer = torch.optim.SGD([w, b], lr=1.0)\n",
    "optimizer = torch.optim.RMSprop([w, b], lr=0.1)\n",
    "\n",
    "\n",
    "for epoch in range(3001):\n",
    "    \n",
    "    h = torch.sigmoid(x_train @ w + b)\n",
    "    cost = torch.mean(-y_train * torch.log(h) - (1 - y_train) * torch.log(1 - h))\n",
    "    \n",
    "    #누적된 기울기 초기화\n",
    "    optimizer.zero_grad()\n",
    "    #기울기, 편향 계산\n",
    "    cost.backward()\n",
    "    \n",
    "    #가중치 업데이트\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, cost.item(), w.item(), b.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, cost:3.1676323413848877\n",
      "epoch:100, cost:0.3585580587387085\n",
      "epoch:200, cost:0.23475299775600433\n",
      "epoch:300, cost:0.16226305067539215\n",
      "epoch:400, cost:0.1186661571264267\n",
      "epoch:500, cost:0.09060386568307877\n",
      "epoch:600, cost:0.071439228951931\n",
      "epoch:700, cost:0.057746630162000656\n",
      "epoch:800, cost:0.047616273164749146\n",
      "epoch:900, cost:0.0399090014398098\n",
      "epoch:1000, cost:0.03390829265117645\n",
      "epoch:1100, cost:0.029144342988729477\n",
      "epoch:1200, cost:0.02529846504330635\n",
      "epoch:1300, cost:0.022148355841636658\n",
      "epoch:1400, cost:0.0195352453738451\n",
      "epoch:1500, cost:0.0173430684953928\n",
      "epoch:1600, cost:0.015485765412449837\n",
      "epoch:1700, cost:0.013898130506277084\n",
      "epoch:1800, cost:0.012530193664133549\n",
      "epoch:1900, cost:0.01134306751191616\n",
      "epoch:2000, cost:0.010306219570338726\n",
      "epoch:2100, cost:0.00939520075917244\n",
      "epoch:2200, cost:0.008590583689510822\n",
      "epoch:2300, cost:0.007876329123973846\n",
      "epoch:2400, cost:0.007239482365548611\n",
      "epoch:2500, cost:0.006669358815997839\n",
      "epoch:2600, cost:0.006157008931040764\n",
      "epoch:2700, cost:0.005694932769984007\n",
      "epoch:2800, cost:0.005276916548609734\n",
      "epoch:2900, cost:0.004897542297840118\n",
      "epoch:3000, cost:0.004552355967462063\n"
     ]
    }
   ],
   "source": [
    "#softmax\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "x_train = torch.tensor([ [1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], [4, 1, 5, 5], [1, 7, 5, 5],\n",
    "                            [1, 2, 5, 6], [1, 6, 6, 6], [1, 7, 7, 7] ], dtype=torch.float)\n",
    "y_train = torch.tensor([ 2, 2, 2, 1, 1, 1, 0, 0], dtype=torch.long)\n",
    "\n",
    "# W = torch.randn(4, 3, requires_grad=True)\n",
    "# b = torch.randn(1, 3, requires_grad=True)\n",
    "\n",
    "# optim = torch.optim.Adam([W, b], lr=0.1)\n",
    "model = nn.Linear(4, 3)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "for epoch in range(3001):\n",
    "    \n",
    "    # h = torch.mm(x_train, W) + b\n",
    "    h = model(x_train)\n",
    "    #cost 계산\n",
    "    \n",
    "    cost = F.cross_entropy(h, y_train)\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    cost.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch:{epoch}, cost:{cost.item()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_train = np.array([ [1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], [4, 1, 5, 5], [1, 7, 5, 5],\n",
    "                            [1, 2, 5, 6], [1, 6, 6, 6], [1, 7, 7, 7] ])\n",
    "y_train = np.array([ 2, 2, 2, 1, 1, 1, 0, 0])\n",
    "\n",
    "#y 에 0, 1, 2 등 둘 이상의 class가 존재 => softmax regression\n",
    "model = LogisticRegression(penalty=None)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "x_test = np.array([[1, 11, 10, 9], [1, 3, 4, 3], [1, 1, 0, 1]])\n",
    "model.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, cost:5.839266300201416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:100, cost:0.24948230385780334\n",
      "epoch:200, cost:0.144336998462677\n",
      "epoch:300, cost:0.09242567420005798\n",
      "epoch:400, cost:0.06418627500534058\n",
      "epoch:500, cost:0.04728551208972931\n",
      "epoch:600, cost:0.036374010145664215\n",
      "epoch:700, cost:0.028905823826789856\n",
      "epoch:800, cost:0.023556703701615334\n",
      "epoch:900, cost:0.01958436332643032\n",
      "epoch:1000, cost:0.01654687151312828\n",
      "epoch:1100, cost:0.014167857356369495\n",
      "epoch:1200, cost:0.012266527861356735\n",
      "epoch:1300, cost:0.010720808990299702\n",
      "epoch:1400, cost:0.009445848874747753\n",
      "epoch:1500, cost:0.008380793035030365\n",
      "epoch:1600, cost:0.0074812378734350204\n",
      "epoch:1700, cost:0.00671401945874095\n",
      "epoch:1800, cost:0.006054043769836426\n",
      "epoch:1900, cost:0.00548198726028204\n",
      "epoch:2000, cost:0.004982654005289078\n",
      "epoch:2100, cost:0.004544231109321117\n",
      "epoch:2200, cost:0.0041569811291992664\n",
      "epoch:2300, cost:0.0038132902700453997\n",
      "epoch:2400, cost:0.0035068022552877665\n",
      "epoch:2500, cost:0.003232380375266075\n",
      "epoch:2600, cost:0.0029856355395168066\n",
      "epoch:2700, cost:0.002763068536296487\n",
      "epoch:2800, cost:0.002561613218858838\n",
      "epoch:2900, cost:0.0023786972742527723\n",
      "epoch:3000, cost:0.0022121421061456203\n"
     ]
    }
   ],
   "source": [
    "#softmax\n",
    "x_train = torch.tensor([ [1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], [4, 1, 5, 5], [1, 7, 5, 5],\n",
    "                            [1, 2, 5, 6], [1, 6, 6, 6], [1, 7, 7, 7] ], dtype=torch.float)\n",
    "y_train = torch.tensor([[0,0,1], [0,0,1], [0,0,1], [0,1,0], [0,1,0], \n",
    "                       [0,1,0], [1,0,0], [1,0,0]], dtype=torch.float)\n",
    "\n",
    "W = torch.randn(4, 3, requires_grad=True)\n",
    "b = torch.randn(1, 3, requires_grad=True)\n",
    "\n",
    "optim = torch.optim.Adam([W, b], lr=0.1)\n",
    "\n",
    "for epoch in range(3001):\n",
    "    #어디를 합을 1로 만들건지(dim=0 or 1)\n",
    "    h = torch.softmax(torch.mm(x_train, W) + b, dim=1)   \n",
    "    #cost 계산\n",
    "    cost = -torch.mean(torch.sum(y_train * torch.log(h), dim=1))\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    cost.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch:{epoch}, cost:{cost.item()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.tensor([[1, 11, 10, 9], [1, 3, 4, 3], [1, 1, 0, 1]], dtype=torch.float)\n",
    "\n",
    "h = torch.softmax(torch.mm(x_test, W) + b, dim = 1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소프트맥스 확률 출력:\n",
      "tensor([[0.6590, 0.2424, 0.0986],\n",
      "        [0.1131, 0.8360, 0.0508],\n",
      "        [0.1220, 0.3315, 0.5465]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 입력 데이터 준비 (logits)\n",
    "logits = torch.tensor([[2.0, 1.0, 0.1],\n",
    "                       [1.0, 3.0, 0.2],\n",
    "                       [0.5, 1.5, 2.0]])\n",
    "\n",
    "# 소프트맥스 적용\n",
    "softmax_probs = F.softmax(logits, dim=1)\n",
    "\n",
    "print(\"소프트맥스 확률 출력:\")\n",
    "print(softmax_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#softmax\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_train = np.array([ [1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], [4, 1, 5, 5], [1, 7, 5, 5],\n",
    "                            [1, 2, 5, 6], [1, 6, 6, 6], [1, 7, 7, 7] ])\n",
    "y_train = np.array([ 2, 2, 2, 1, 1, 1, 0, 0])\n",
    "\n",
    "model = LogisticRegression(penalty=None)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "x_test = np.array([[1, 11, 10, 9], [1, 3, 4, 3], [1, 1, 0, 1]])\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy 손실: 0.8106180429458618\n",
      "Binary Cross Entropy 손실: 0.14462153613567352\n"
     ]
    }
   ],
   "source": [
    "#cross entropy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 다중 클래스 예제 (CrossEntropyLoss)\n",
    "y_true = torch.tensor([2, 0])  # 실제 값 (원-핫 인코딩이 아님, 클래스 인덱스로 전달)\n",
    "y_pred = torch.tensor([[0.1, 0.3, 0.6], [0.7, 0.2, 0.1]])  # 예측 값 (로짓 값)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(y_pred, y_true)\n",
    "print(f\"Cross Entropy 손실: {loss.item()}\")\n",
    "\n",
    "# 이진 분류 예제 (BCELoss)\n",
    "y_true_binary = torch.tensor([1.0, 0.0, 1.0])  # 실제 값\n",
    "y_pred_binary = torch.tensor([0.9, 0.1, 0.8])  # 예측 값\n",
    "\n",
    "bce_criterion = nn.BCELoss()\n",
    "bce_loss = bce_criterion(y_pred_binary, y_true_binary)\n",
    "print(f\"Binary Cross Entropy 손실: {bce_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/500], Loss: 1.2751\n",
      "Epoch [50/500], Loss: 0.8543\n",
      "Epoch [100/500], Loss: 0.5934\n",
      "Epoch [150/500], Loss: 0.4299\n",
      "Epoch [200/500], Loss: 0.3243\n",
      "Epoch [250/500], Loss: 0.2531\n",
      "Epoch [300/500], Loss: 0.2032\n",
      "Epoch [350/500], Loss: 0.1670\n",
      "Epoch [400/500], Loss: 0.1398\n",
      "Epoch [450/500], Loss: 0.1189\n",
      "Predicted class for tensor([[1., 0.]]): 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 데이터셋 준비\n",
    "x_train = torch.tensor([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0], [0.0, 0.0]])\n",
    "y_train = torch.tensor([0, 1, 2, 3])  # 클래스 레이블 (0, 1, 2, 3)\n",
    "\n",
    "# 모델 정의\n",
    "class SoftmaxClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SoftmaxClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)  # 입력과 출력 연결\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = SoftmaxClassifier(input_dim=2, output_dim=4)\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()  # 내부적으로 Softmax 포함\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  # Adam Optimizer 사용\n",
    "\n",
    "# 학습 반복 (Epoch Loop)\n",
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    # Forward Propagation\n",
    "    output = model(x_train)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = criterion(output, y_train)\n",
    "\n",
    "    # Gradient 초기화, Backpropagation, 가중치 업데이트\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 중간 결과 출력\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 테스트\n",
    "test_input = torch.tensor([[1.0, 0.0]])  # 새로운 데이터 예측\n",
    "test_output = model(test_input)\n",
    "predicted_class = torch.argmax(test_output, dim=1)\n",
    "print(f\"Predicted class for {test_input}: {predicted_class.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 포인트 정의\n",
    "data = np.array([[1, 2], [2, 1], [4, 5], [5, 4], [8, 8], [9, 9]])\n",
    "\n",
    "# WCSS 저장 리스트\n",
    "wcss = []\n",
    "\n",
    "# 다양한 K 값에 대해 K-Means 수행 (데이터 포인트 개수를 초과하지 않도록 설정)\n",
    "for k in range(1, len(data) + 1):\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "    kmeans.fit(data)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# 엘보우 방법을 위한 그래프 그리기\n",
    "plt.plot(range(1, len(data) + 1), wcss)\n",
    "plt.title('elbow')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('WCSS (Within-Cluster Sum of Squares)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for line in open(\"iris.data\", \"r\"):\n",
    "    line = line.rstrip()\n",
    "    if line == \"\": continue\n",
    "\n",
    "    *x, y = line.split(\",\")\n",
    "    x = [float(i) for i in x]\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    \n",
    "\n",
    "labels = list(set(Y))\n",
    "Y = [labels.index(y) for y in Y]\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def predict(self, queries):\n",
    "        Y = []\n",
    "        for q in queries:\n",
    "            dists = np.linalg.norm(self.X - q, axis = 1)\n",
    "            knns= np.argsort(dists)[:self.k]\n",
    "            counts = np.bincount(self.Y[knns])\n",
    "            Y.append(np.argmax(counts))\n",
    "\n",
    "        return np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9916666666666667\n",
      "Test accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "perm = np.random.permutation(len(X))\n",
    "n_trains = int(len(X) * 0.8)\n",
    "X_train = X[perm[:n_trains]]\n",
    "Y_train = Y[perm[:n_trains]]\n",
    "X_test = X[perm[n_trains:]]\n",
    "Y_test = Y[perm[n_trains:]]\n",
    "\n",
    "knn = KNNClassifier(5)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "pred_train = knn.predict(X_train)\n",
    "pred_test = knn.predict(X_test)\n",
    "\n",
    "print(\"Train accuracy:\", (pred_train == Y_train).mean())\n",
    "print(\"Test accuracy:\", (pred_test == Y_test).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
